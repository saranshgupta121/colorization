{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image colorisation_5000_unspalsh_data.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saranshgupta121/colorization/blob/master/image_colorisation_5000_unspalsh_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "sw8_eJVGuNTY",
        "colab_type": "code",
        "outputId": "127284ed-3276-4424-8727-7bf419f8ac51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YlrF9MScuhIT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Sequential, Model\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense,Flatten,Conv2D,Activation\n",
        "import numpy as np\n",
        "from keras import layers\n",
        "import keras\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import Conv2D, UpSampling2D,MaxPooling2D, InputLayer, Conv2DTranspose, Input, Reshape, merge, concatenate\n",
        "from keras.layers import Activation, Dense, Dropout, Flatten\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.callbacks import TensorBoard \n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers.core import RepeatVector, Permute\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n",
        "from skimage.transform import resize\n",
        "from skimage.io import imsave\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from keras.models import model_from_json\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BaI-uK2IzQW3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import load_img\n",
        "# load an image from file\n",
        "image = load_img('/content/drive/My Drive/colorization dataset 5000/cat.34.jpg', target_size=(224, 224))\n",
        "from keras.preprocessing.image import img_to_array\n",
        "# convert the image pixels to a numpy array\n",
        "image = img_to_array(image)\n",
        "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "# prepare the image for the VGG model\n",
        "image = preprocess_input(image)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1wbh0fTn8JYP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_shape=[224,224,3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kg3yVOXhvLqE",
        "colab_type": "code",
        "outputId": "f625b35b-dd54-4100-b0d9-5ff1d8c578f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "vgg16 = Sequential([\n",
        "Conv2D(64, (3, 3), input_shape=input_shape, padding='same', activation='relu'),\n",
        "Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "Conv2D(128, (3, 3), activation='relu', padding='same',),\n",
        "MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "Conv2D(256, (3, 3), activation='relu', padding='same',),\n",
        "Conv2D(256, (3, 3), activation='relu', padding='same',),\n",
        "Conv2D(256, (3, 3), activation='relu', padding='same',),\n",
        "MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
        "Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
        "Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
        "MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
        "Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
        "Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
        "MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "Flatten(),\n",
        "Dense(4096, activation='relu'),\n",
        "Dense(4096, activation='relu'),\n",
        "Dense(1000,),\n",
        "Activation('softmax')\n",
        "])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pNwIJg448P2w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "outputId": "4c1b61b8-4087-4b28-8b90-c73c2bce62fe"
      },
      "cell_type": "code",
      "source": [
        "vgg16.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1000)              4097000   \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 1000)              0         \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GWvHzUPCD_oI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vgg16.load_weights('/content/drive/My Drive/vgg16_weights.h5', by_name=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jlY-HC84Oqs8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "layer_name = 'dense_3'\n",
        "intermediate_layer_model = Model(inputs=vgg16.input,\n",
        "                                 outputs=vgg16.get_layer(layer_name).output)\n",
        "vgg16.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ACdZYoqRuInX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vgg16.graph = tf.get_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DkGZfFcckIHh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = []\n",
        "for filename in os.listdir('/content/drive/My Drive/5000_random_unsplash'):\n",
        "    X.append(img_to_array(load_img('/content/drive/My Drive/5000_random_unsplash/'+filename,target_size=(256, 256))))\n",
        "    #print(len(X))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "__yLqgRBkaIT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = np.array(X,dtype=np.float32)\n",
        "Xtrain = 1.0/255*X\n",
        "print(len(Xtrain))\n",
        "#plt.imshow(Xtrain[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fuim3tiYlyPl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embed_input = Input(shape=(1000,))\n",
        "#Encoder\n",
        "encoder_input = Input(shape=(256, 256, 1,))\n",
        "encoder_output = Conv2D(64, (3,3), activation='relu', padding='same', strides=2)(encoder_input)\n",
        "encoder_output = Conv2D(128, (3,3), activation='relu', padding='same', strides =2)(encoder_output)\n",
        "encoder_output = Conv2D(128, (3,3), activation='relu', padding='same', strides=2)(encoder_output)\n",
        "encoder_output = BatchNormalization()(encoder_output)\n",
        "encoder_output = Conv2D(256, (3,3), activation='relu', padding='same', strides=2)(encoder_output)\n",
        "encoder_output = Conv2D(256, (3,3), activation='relu', padding='same', strides=2)(encoder_output)\n",
        "encoder_output = Conv2D(512, (3,3), activation='relu', padding='same', strides=2)(encoder_output)\n",
        "\n",
        "#Fusion\n",
        "fusion_output = RepeatVector(4 *4)(embed_input) \n",
        "fusion_output = Reshape(([4,4,1000]))(fusion_output)\n",
        "fusion_output = concatenate([encoder_output, fusion_output], axis=3) \n",
        "fusion_output = Conv2D(512, (1, 1), activation='relu', padding='same')(fusion_output)\n",
        "\n",
        "decoder_output = Conv2DTranspose(512, (3,3), activation='relu', padding='same', strides=1)(encoder_output)\n",
        "decoder_output = Conv2DTranspose(256, (3,3), activation='relu', padding='same', strides=2)(decoder_output)\n",
        "decoder_output = Conv2DTranspose(256, (3,3), activation='relu', padding='same', strides=2)(decoder_output)\n",
        "decoder_output = Conv2DTranspose(128, (3,3), activation='relu', padding='same', strides=2)(decoder_output)\n",
        "decoder_output = BatchNormalization()(decoder_output)\n",
        "decoder_output = Conv2DTranspose(128, (3,3), activation='relu', padding='same', strides=2)(decoder_output)\n",
        "decoder_output = Conv2DTranspose(64, (3,3), activation='relu', padding='same', strides=2)(decoder_output)\n",
        "decoder_output = Conv2DTranspose(32, (3,3), activation='relu', padding='same', strides=2)(decoder_output)\n",
        "decoder_output = Conv2DTranspose(2, (1,1), activation='relu', padding='same', strides=1)(decoder_output)\n",
        "\n",
        "model = Model(inputs=[encoder_input,embed_input], outputs=decoder_output)\n",
        "#model = Model(inputs=[encoder_input], outputs=decoder_output)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7i7OIkZSmRk1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "24dd35c6-29fd-41cd-dcd4-f9ff510023cc"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         (None, 256, 256, 1)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 128, 128, 64)      640       \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 64, 64, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 32, 32, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 16, 16, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 4, 4, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_9 (Conv2DTr (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_10 (Conv2DT (None, 8, 8, 256)         1179904   \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_11 (Conv2DT (None, 16, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_12 (Conv2DT (None, 32, 32, 128)       295040    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_13 (Conv2DT (None, 64, 64, 128)       147584    \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_14 (Conv2DT (None, 128, 128, 64)      73792     \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_15 (Conv2DT (None, 256, 256, 32)      18464     \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_16 (Conv2DT (None, 256, 256, 2)       66        \n",
            "=================================================================\n",
            "Total params: 6,953,250\n",
            "Trainable params: 6,952,738\n",
            "Non-trainable params: 512\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sSjYwaGGmUFE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_classifier_embedding(grayscaled_rgb):\n",
        "    grayscaled_rgb_resized = []\n",
        "    for i in grayscaled_rgb:\n",
        "        i = resize(i, (224, 224, 3), mode='constant')\n",
        "        grayscaled_rgb_resized.append(i)\n",
        "    grayscaled_rgb_resized = np.array(grayscaled_rgb_resized)\n",
        "    #grayscaled_rgb_resized = preprocess_input(grayscaled_rgb_resized)\n",
        "    with vgg16.graph.as_default():\n",
        "        embed = vgg16.predict(grayscaled_rgb_resized)\n",
        "        embed = intermediate_layer_model.predict(grayscaled_rgb_resized)\n",
        "    return embed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GyoB6zIfmXBS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        rotation_range=20,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "#Generate training data\n",
        "batch_size = 2\n",
        "\n",
        "def image_a_b_gen(batch_size):\n",
        "    for batch in datagen.flow(Xtrain, batch_size=batch_size):\n",
        "        grayscaled_rgb = gray2rgb(rgb2gray(batch))\n",
        "        embed = create_classifier_embedding(grayscaled_rgb)\n",
        "        lab_batch = rgb2lab(batch)\n",
        "        X_batch = lab_batch[:,:,:,0]\n",
        "        X_batch = X_batch.reshape(X_batch.shape+(1,))\n",
        "        Y_batch = lab_batch[:,:,:,1:] / 128\n",
        "        #yield (X_batch, Y_batch)\n",
        "        yield ([X_batch,create_classifier_embedding(grayscaled_rgb)], Y_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ATCwW0B2Zrq1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "54ca6378-7366-4ba3-8797-ed461b3d049d"
      },
      "cell_type": "code",
      "source": [
        "color_me = []\n",
        "for filename in os.listdir('/content/drive/My Drive/colorization_unsplash_20_test'):\n",
        "  color_me.append(img_to_array(load_img('/content/drive/My Drive/colorization_unsplash_20_test/'+filename,target_size=(256, 256))))\n",
        "len(color_me)\n",
        "#plt.imshow(color_me[0])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "metadata": {
        "id": "FEemNEVNoW83",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "color_me = np.array(color_me, dtype=float)\n",
        "#print(color_me.shape)\n",
        "\n",
        "gray_me = gray2rgb(rgb2gray(color_me/255.0))\n",
        "color_me_embed = create_classifier_embedding(gray_me)\n",
        "color_me = rgb2lab(1.0/255*color_me)[:,:,:,0]\n",
        "color_me_duplicate=color_me\n",
        "\n",
        "#color_me_duplicate=gray_me"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kd-s06qwmkAx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Train model      \n",
        "model.compile(optimizer=Adam(lr=0.001), loss='mse',metrics=[\"accuracy\"])\n",
        "#model.compile(optimizer=Adam(lr=0.01), loss='mse',metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_XwFl4FskpmC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filepath=\"/content/drive/My Drive/image colorisation_20_unspalsh_data_results/weights.{epoch:02d}-{loss:.2f}.hdf5\"\n",
        "checkpoint=ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=False, save_weights_only=True, mode='auto', period=100)\n",
        "callbacks_list = [checkpoint]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UDJctM9GkuHy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(20):\n",
        "  history=model.fit_generator(image_a_b_gen(batch_size), epochs=100, steps_per_epoch=5,verbose=1,callbacks=callbacks_list)\n",
        "  output = model.predict([color_me,color_me_embed])\n",
        "  #output = model.predict(color_me)\n",
        "  output = output * 128\n",
        "  if((i+1)%2==0):\n",
        "    for j in range(len(output)):\n",
        "      cur = np.zeros((256, 256, 3))\n",
        "      cur[:,:,0] = color_me[j][:,:,0]\n",
        "      cur[:,:,1:] = output[j]\n",
        "      #axarr[c,0].imshow(color_me_duplicate[i])\n",
        "      imsave('/content/drive/My Drive/image colorisation_20_unspalsh_data_results/'+'epochs_'+str((i+1)*100)+'/'+'input_sketches'+str(j)+'.png',color_me_duplicate[j])\n",
        "      #axarr[c][0].axis('off')\n",
        "      #axarr[c,1].imshow(lab2rgb(cur))\n",
        "      imsave('/content/drive/My Drive/image colorisation_20_unspalsh_data_results/'+'epochs_'+str((i+1)*100)+'/'+'output_sketches'+str(j)+'.png', lab2rgb(cur))\n",
        "      #axarr[c][1].axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KirFOzNP4FsH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}